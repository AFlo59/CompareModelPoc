"""
Page des param√®tres utilisateur
"""

import streamlit as st
from src.auth.auth import require_auth
from src.data.models import get_user_campaigns, get_user_model_choice, save_model_choice

def show_settings_page() -> None:
    """Page d√©di√©e aux param√®tres globaux de l'application."""
    if not require_auth():
        return

    st.title("‚öôÔ∏è Param√®tres de l'application")

    # Bouton retour au dashboard
    if st.button("üè† Retour au tableau de bord"):
        st.session_state.page = "dashboard"
        st.rerun()

    st.divider()

    # Informations utilisateur
    st.markdown("### üë§ Informations du compte")
    user_email = st.session_state.user.get("email", "Non d√©fini")
    st.info(f"**Email :** {user_email}")

    # Statistiques globales
    try:
        campaigns = get_user_campaigns(st.session_state.user["id"])
        total_campaigns = len(campaigns)
        total_messages = sum(camp.get("message_count", 0) for camp in campaigns)
    except:
        total_campaigns = 0
        total_messages = 0

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("üìö Campagnes cr√©√©es", total_campaigns)
    with col2:
        st.metric("üí¨ Messages totaux", total_messages)
    with col3:
        st.metric("ü§ñ Mod√®les utilis√©s", "Multiple")

    st.divider()

    # Pr√©f√©rences de mod√®le
    st.markdown("### ü§ñ Pr√©f√©rences de mod√®le IA")
    
    # Mod√®les disponibles (devrait √™tre import√© de config)
    available_models = ["GPT-4", "GPT-4o", "Claude 3.5 Sonnet", "DeepSeek"]
    
    # Mod√®le actuellement s√©lectionn√©
    try:
        current_model = get_user_model_choice(st.session_state.user["id"])
        if current_model not in available_models:
            current_model = available_models[0]  # Fallback
    except:
        current_model = available_models[0]

    # S√©lecteur de mod√®le par d√©faut
    selected_model = st.selectbox(
        "Choisissez votre mod√®le IA par d√©faut:",
        available_models,
        index=available_models.index(current_model) if current_model in available_models else 0,
        help="Ce mod√®le sera s√©lectionn√© par d√©faut lors de vos prochaines sessions de chat"
    )

    if st.button("üíæ Sauvegarder les pr√©f√©rences"):
        try:
            save_model_choice(st.session_state.user["id"], selected_model)
            st.success(f"‚úÖ Mod√®le par d√©faut sauvegard√© : {selected_model}")
        except Exception as e:
            st.error(f"‚ùå Erreur lors de la sauvegarde : {e}")

    # Informations sur les mod√®les
    st.divider()
    st.markdown("### üìä Informations sur les mod√®les")
    
    model_info = {
        "GPT-4": {"icon": "üß†", "desc": "Le plus avanc√©, excellent pour la cr√©ativit√©", "cost": "$$$$"},
        "GPT-4o": {"icon": "‚ö°", "desc": "Version optimis√©e, plus rapide et √©conomique", "cost": "$$$"},
        "Claude 3.5 Sonnet": {"icon": "üé≠", "desc": "Excellent pour le roleplay et la narration", "cost": "$$$"},
        "DeepSeek": {"icon": "üí∞", "desc": "Alternative √©conomique, bon rapport qualit√©/prix", "cost": "$"}
    }
    
    for model, info in model_info.items():
        with st.expander(f"{info['icon']} {model}"):
            st.write(f"**Description:** {info['desc']}")
            st.write(f"**Co√ªt relatif:** {info['cost']}")

    st.divider()
    
    # Section aide
    st.markdown("### ‚ùì Aide et support")
    st.markdown("""
    - **Probl√®me technique ?** V√©rifiez que vos cl√©s API sont bien configur√©es
    - **Performance lente ?** Essayez GPT-4o pour des r√©ponses plus rapides
    - **Budget limit√© ?** DeepSeek offre un bon rapport qualit√©/prix
    - **Roleplay immersif ?** Claude 3.5 Sonnet excelle dans la narration
    """)
