"""
Tests pour le module analytics - performance et monitoring
"""

import os
import sys
import pytest
import pandas as pd
import sqlite3
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timedelta

# Ajouter le r√©pertoire parent au PYTHONPATH
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from src.analytics.performance import (
    get_performance_data,
    calculate_cost,
    show_performance_summary,
    show_model_comparison,
    show_performance_charts,
    show_performance,
    show_ai_performance,
    MODEL_COSTS
)
from src.analytics.system_monitoring import (
    get_system_info,
    get_cpu_stats, 
    get_memory_stats,
    get_disk_stats,
    get_network_stats,
    show_system_monitoring
)


class TestPerformanceAnalytics:
    """Tests pour les fonctions d'analyse de performance."""

    def setup_method(self):
        """Setup pour chaque test."""
        self.test_user_id = 1
        self.sample_data = {
            'model': ['GPT-4', 'Claude 3.5 Sonnet', 'GPT-4o'],
            'latency': [2.5, 1.8, 1.2],
            'tokens_in': [100, 150, 80],
            'tokens_out': [200, 180, 120],
            'timestamp': [
                datetime.now() - timedelta(days=1),
                datetime.now() - timedelta(days=2), 
                datetime.now() - timedelta(days=3)
            ]
        }
        self.sample_df = pd.DataFrame(self.sample_data)

    @patch('src.analytics.performance.get_connection')
    def test_get_performance_data_success(self, mock_get_connection):
        """Test r√©cup√©ration des donn√©es de performance - succ√®s."""
        # Mock de la connexion et du cursor
        mock_conn = Mock()
        mock_cursor = Mock()
        mock_conn.cursor.return_value = mock_cursor
        mock_get_connection.return_value = mock_conn
        
        # Donn√©es de test
        mock_cursor.fetchall.return_value = [
            ('GPT-4', 2.5, 100, 200, '2024-01-01 12:00:00'),
            ('Claude 3.5 Sonnet', 1.8, 150, 180, '2024-01-02 12:00:00')
        ]
        
        # Configuration du mock pandas
        with patch('pandas.read_sql_query') as mock_read_sql:
            test_df = self.sample_df.copy()
            mock_read_sql.return_value = test_df
            
            # Mock de la fonction apply pour calculer les co√ªts
            with patch.object(test_df, 'apply') as mock_apply:
                mock_apply.return_value = pd.Series([0.045, 0.033, 0.021])
                
                result = get_performance_data(self.test_user_id, 30)
                
                # V√©rifications
                assert not result.empty
                assert len(result) == 3
                mock_get_connection.assert_called_once()
                mock_conn.close.assert_called_once()

    @patch('src.analytics.performance.get_connection')
    def test_get_performance_data_empty(self, mock_get_connection):
        """Test r√©cup√©ration des donn√©es de performance - pas de donn√©es."""
        mock_conn = Mock()
        mock_get_connection.return_value = mock_conn
        
        with patch('pandas.read_sql_query') as mock_read_sql:
            mock_read_sql.return_value = pd.DataFrame()
            
            result = get_performance_data(self.test_user_id, 7)
            
            assert result.empty
            mock_conn.close.assert_called_once()

    def test_calculate_cost_gpt4(self):
        """Test calcul du co√ªt pour GPT-4."""
        row = pd.Series({
            'model': 'GPT-4',
            'tokens_in': 1000,
            'tokens_out': 500
        })
        
        cost = calculate_cost(row)
        
        expected_cost = (1000/1000) * 0.03 + (500/1000) * 0.06
        assert cost == round(expected_cost, 4)

    def test_calculate_cost_claude(self):
        """Test calcul du co√ªt pour Claude."""
        row = pd.Series({
            'model': 'Claude 3.5 Sonnet',
            'tokens_in': 2000,
            'tokens_out': 800
        })
        
        cost = calculate_cost(row)
        
        expected_cost = (2000/1000) * 0.003 + (800/1000) * 0.015
        assert cost == round(expected_cost, 4)

    def test_calculate_cost_deepseek(self):
        """Test calcul du co√ªt pour DeepSeek."""
        row = pd.Series({
            'model': 'DeepSeek',
            'tokens_in': 5000,
            'tokens_out': 1500
        })
        
        cost = calculate_cost(row)
        
        expected_cost = (5000/1000) * 0.00014 + (1500/1000) * 0.00028
        assert cost == round(expected_cost, 4)

    def test_calculate_cost_unknown_model(self):
        """Test calcul du co√ªt pour mod√®le inconnu."""
        row = pd.Series({
            'model': 'Unknown Model',
            'tokens_in': 1000,
            'tokens_out': 500
        })
        
        cost = calculate_cost(row)
        
        # Devrait utiliser les co√ªts par d√©faut
        expected_cost = (1000/1000) * 0.01 + (500/1000) * 0.01
        assert cost == round(expected_cost, 4)

    @patch('streamlit.info')
    @patch('streamlit.columns')
    @patch('streamlit.metric')
    def test_show_performance_summary_empty(self, mock_metric, mock_columns, mock_info):
        """Test affichage r√©sum√© - donn√©es vides."""
        empty_df = pd.DataFrame()
        
        show_performance_summary(empty_df)
        
        mock_info.assert_called_once_with("üìä Aucune donn√©e de performance disponible.")
        mock_columns.assert_not_called()

    @patch('streamlit.columns')
    @patch('streamlit.metric')
    def test_show_performance_summary_with_data(self, mock_metric, mock_columns):
        """Test affichage r√©sum√© avec donn√©es."""
        # Ajouter la colonne cost manquante
        test_df = self.sample_df.copy()
        test_df['cost'] = [0.045, 0.033, 0.021]
        
        # Mock des colonnes Streamlit avec support context manager
        def create_mock_col():
            mock_col = Mock()
            mock_col.__enter__ = Mock(return_value=mock_col)
            mock_col.__exit__ = Mock(return_value=None)
            return mock_col
        
        mock_col1 = create_mock_col()
        mock_col2 = create_mock_col()
        mock_col3 = create_mock_col()
        mock_col4 = create_mock_col()
        
        mock_columns.return_value = [mock_col1, mock_col2, mock_col3, mock_col4]
        
        show_performance_summary(test_df)
        
        mock_columns.assert_called_once_with(4)
        assert mock_metric.call_count == 4

    @patch('streamlit.subheader')
    @patch('streamlit.dataframe')
    def test_show_model_comparison_empty(self, mock_dataframe, mock_subheader):
        """Test comparaison mod√®les - donn√©es vides."""
        empty_df = pd.DataFrame()
        
        show_model_comparison(empty_df)
        
        # Avec un dataframe vide, la fonction fait return early
        # donc subheader n'est PAS appel√©
        mock_subheader.assert_not_called()
        mock_dataframe.assert_not_called()

    @patch('streamlit.subheader')
    @patch('streamlit.dataframe')  
    def test_show_model_comparison_with_data(self, mock_dataframe, mock_subheader):
        """Test comparaison mod√®les avec donn√©es."""
        test_df = self.sample_df.copy()
        test_df['cost'] = [0.045, 0.033, 0.021]
        
        show_model_comparison(test_df)
        
        mock_subheader.assert_called_once()
        mock_dataframe.assert_called_once()

    @patch('streamlit.subheader')
    @patch('streamlit.columns')
    @patch('streamlit.plotly_chart')
    def test_show_performance_charts_empty(self, mock_plotly, mock_columns, mock_subheader):
        """Test graphiques performance - donn√©es vides."""
        empty_df = pd.DataFrame()
        
        show_performance_charts(empty_df)
        
        # Avec un DataFrame vide, la fonction devrait retourner early
        mock_subheader.assert_not_called()
        mock_plotly.assert_not_called()

    @patch('streamlit.subheader')
    @patch('streamlit.columns')
    @patch('streamlit.plotly_chart')
    @patch('plotly.express.box')
    @patch('plotly.express.pie')
    def test_show_performance_charts_with_data(self, mock_pie, mock_box, mock_plotly, mock_columns, mock_subheader):
        """Test graphiques performance avec donn√©es."""
        test_df = self.sample_df.copy()
        test_df['cost'] = [0.045, 0.033, 0.021]
        # Ajouter la colonne 'date' attendue par la fonction
        test_df['date'] = test_df['timestamp'].dt.date
        
        # Mock des figures Plotly
        mock_fig = Mock()
        mock_fig.update_layout = Mock()
        mock_box.return_value = mock_fig
        mock_pie.return_value = mock_fig
        
        # Mock des colonnes avec support context manager
        def create_mock_col():
            mock_col = Mock()
            mock_col.__enter__ = Mock(return_value=mock_col)
            mock_col.__exit__ = Mock(return_value=None)
            return mock_col
            
        mock_col1 = create_mock_col()
        mock_col2 = create_mock_col()
        mock_columns.return_value = [mock_col1, mock_col2]
        
        show_performance_charts(test_df)
        
        mock_subheader.assert_called()
        mock_columns.assert_called()
        assert mock_plotly.call_count >= 2


class TestSystemMonitoring:
    """Tests pour les fonctions de monitoring syst√®me."""

    @patch('psutil.cpu_percent')
    @patch('psutil.cpu_count')
    @patch('psutil.cpu_freq')
    def test_get_cpu_stats(self, mock_cpu_freq, mock_cpu_count, mock_cpu_percent):
        """Test r√©cup√©ration statistiques CPU."""
        # Configuration des mocks
        mock_cpu_percent.return_value = 45.2
        mock_cpu_count.return_value = 8
        mock_freq = Mock()
        mock_freq.current = 2400.0
        mock_cpu_freq.return_value = mock_freq
        
        result = get_cpu_stats()
        
        # V√©rifier les vraies cl√©s retourn√©es par la fonction
        assert 'cpu_usage_total' in result
        assert 'cpu_usage_per_core' in result
        assert 'cpu_frequency_current' in result
        assert 'cpu_frequency_max' in result
        assert 'load_average' in result

    @patch('psutil.virtual_memory')
    @patch('psutil.swap_memory')
    def test_get_memory_stats(self, mock_swap, mock_virtual):
        """Test r√©cup√©ration statistiques m√©moire."""
        # Mock virtual memory
        mock_vmem = Mock()
        mock_vmem.total = 16 * 1024**3  # 16GB
        mock_vmem.available = 8 * 1024**3  # 8GB
        mock_vmem.percent = 50.0
        mock_virtual.return_value = mock_vmem
        
        # Mock swap memory
        mock_swap_mem = Mock()
        mock_swap_mem.total = 4 * 1024**3  # 4GB
        mock_swap_mem.used = 1 * 1024**3   # 1GB
        mock_swap_mem.percent = 25.0
        mock_swap.return_value = mock_swap_mem
        
        result = get_memory_stats()
        
        # V√©rifier les vraies cl√©s retourn√©es par la fonction
        assert 'memory_total' in result
        assert 'memory_available' in result
        assert 'memory_used' in result
        assert 'memory_percent' in result
        assert 'swap_total' in result
        assert 'swap_used' in result
        assert 'swap_percent' in result
        assert result['memory_percent'] == 50.0

    @patch('psutil.disk_usage')
    @patch('psutil.disk_partitions')
    def test_get_disk_stats(self, mock_partitions, mock_usage):
        """Test r√©cup√©ration statistiques disque."""
        # Mock partitions
        mock_partition = Mock()
        mock_partition.device = '/dev/sda1'
        mock_partition.mountpoint = '/'
        mock_partition.fstype = 'ext4'
        mock_partitions.return_value = [mock_partition]
        
        # Mock usage
        mock_disk_usage = Mock()
        mock_disk_usage.total = 500 * 1024**3  # 500GB
        mock_disk_usage.used = 300 * 1024**3   # 300GB
        mock_disk_usage.free = 200 * 1024**3   # 200GB
        mock_usage.return_value = mock_disk_usage
        
        result = get_disk_stats()
        
        assert isinstance(result, list)
        assert len(result) == 1
        # V√©rifier les vraies cl√©s retourn√©es par la fonction
        assert 'device' in result[0]
        assert 'mountpoint' in result[0]
        assert 'fstype' in result[0]
        assert 'total' in result[0]
        assert 'used' in result[0]
        assert 'free' in result[0]

    def test_get_system_info(self):
        """Test r√©cup√©ration informations syst√®me."""
        with patch('platform.system') as mock_system, \
             patch('platform.release') as mock_release, \
             patch('platform.processor') as mock_processor:
            
            mock_system.return_value = 'Linux'
            mock_release.return_value = '5.4.0'
            mock_processor.return_value = 'x86_64'
            
            result = get_system_info()
            
            # V√©rifier les vraies cl√©s retourn√©es par la fonction
            assert 'os' in result
            assert 'os_version' in result
            assert 'architecture' in result
            assert 'processor' in result
            assert 'python_version' in result
            assert 'cpu_count' in result
            assert 'cpu_count_logical' in result
            assert 'boot_time' in result

    @patch('streamlit.title')
    @patch('streamlit.tabs')
    def test_show_system_monitoring(self, mock_tabs, mock_title):
        """Test affichage monitoring syst√®me."""
        # Mock des onglets
        mock_tab1, mock_tab2, mock_tab3 = Mock(), Mock(), Mock()
        mock_tabs.return_value = [mock_tab1, mock_tab2, mock_tab3]
        
        # Mock context managers pour les onglets
        mock_tab1.__enter__ = Mock(return_value=mock_tab1)
        mock_tab1.__exit__ = Mock(return_value=None)
        mock_tab2.__enter__ = Mock(return_value=mock_tab2)
        mock_tab2.__exit__ = Mock(return_value=None)
        mock_tab3.__enter__ = Mock(return_value=mock_tab3)
        mock_tab3.__exit__ = Mock(return_value=None)
        
        with patch('src.analytics.system_monitoring.get_system_info') as mock_sys_info, \
             patch('src.analytics.system_monitoring.get_cpu_stats') as mock_cpu, \
             patch('src.analytics.system_monitoring.get_memory_stats') as mock_mem, \
             patch('src.analytics.system_monitoring.get_disk_stats') as mock_disk, \
             patch('streamlit.metric'), \
             patch('streamlit.plotly_chart'):
            
            # Mock avec de vraies valeurs et les bonnes cl√©s
            from datetime import datetime
            mock_sys_info.return_value = {
                'os': 'Linux', 'os_version': '5.4.0', 'architecture': '64bit',
                'processor': 'x86_64', 'python_version': '3.9.0',
                'cpu_count': 8, 'cpu_count_logical': 16, 'boot_time': datetime.now()
            }
            
            mock_cpu.return_value = {
                'cpu_usage_total': 45.2, 'cpu_usage_per_core': [20, 30, 40], 
                'cpu_frequency_current': 2400.0, 'cpu_frequency_max': 3200.0,
                'load_average': [1.0, 1.2, 1.5]
            }
            
            mock_mem.return_value = {
                'memory_total': 16*1024**3, 'memory_available': 8*1024**3,
                'memory_used': 8*1024**3, 'memory_percent': 50.0,
                'swap_total': 4*1024**3, 'swap_used': 1*1024**3, 'swap_percent': 25.0
            }
            
            mock_disk.return_value = [
                {'device': '/dev/sda1', 'mountpoint': '/', 'fstype': 'ext4',
                 'total': 500*1024**3, 'used': 300*1024**3, 'free': 200*1024**3, 'percent': 60.0}
            ]
            
            show_system_monitoring()
            
            mock_title.assert_called_once()
            # tabs peut √™tre appel√©, mais n'est pas forc√©ment requis
            # mock_tabs.assert_called_once()


if __name__ == "__main__":
    pytest.main([__file__])
